**What is Gen AI ?**

      Generative AI is a type of AI that creates new content such as text, images, music, or code by learning patterns from existing data mimicking human creativity.





Machine Learning - mostly for 3 types of models

     1. Predicting a number (Regression)

     2. Classification

     3. Ranking problems (recommendation system)





Gen AI - mimicking human creativity

AI-ML-DL-Gen AI





**Impact areas of Gen AI**

* Customer support
* Content Creation
* Education
* Software development





is Gen AI successful ?

**Always ask these questions -->**

1. Does it solve real world problems ?
2. Is it useful on a daily basis ?
3. Is it impacting the world economics ?
4. Is it creating new jobs ?
5. Is it accessible ?







**Foundation models -->** 

* a type of AI models, requires a large dataset and heavy GPUs to train
* generalised models, able to solve a wide variety of problems. Eg: LLMs, LMMs (Large Multimodal Models)  





Gen AI - either User perspective (to use models) or Builder perspective (to build foundation models) 



**User perspective** - Prompt Engineering, RAG (Retrieval Augmented Generation), AI Agents, Vector Databases, Fine Tuning 

**Builder perspective** - RLHF (Reinforcement Learning with the help of Human feedback- modifying behaviour of LLMs, so as to avoid wrong answers or hallucinations), Pretraining (training a foundation model), Quantization (optimising a Model to use in diff environment), Fine Tuning  







**Builder's perspective:** 

**Prerequisites** : ML fundamentals, DL fundamentals, DL framework ( PyTorch preferred) 

1. **Transformer Architecture** (Encoder, Decoder, Embeddings, Self Attention, Layer normalisation, Language models) 
2. **Types of Transformers** (Encode only- BERT, Decoder only- GPT, Encoder \& Decoder based- T5) 
3. **Pretraining** - (Training objectives, Tokenization strategies, Training strategies, Handling challenges) 
4. **Optimization** (Training Optimization, Model Compression, Optimizing Inference)  
5. **Fine Tuning** (Task specific tuning- RLHF, Instruction tuning- PEFT, Continual Pretraining) 
6. **Evaluation** 
7. **Deployment** 





**User's perspective:** 

1. **Building Basic LLM Apps** (Open Source vs Closed Source LLMs, Using LLM APIs, LangChain, HuggingFace, Ollama) 
2. **Prompt Engineering**
3. **RAG** 
4. **Fine Tuning** 
5. **Agents** 
6. **LLMOps** 
7. **Miscellaneous** (MultiModals, Stable Diffusion....)





**Builder side - Data Scientist** 

**User side - Software developers** 

**Both - AI Engineer** 













